import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import logging
from tqdm import tqdm
import os
from pathlib import Path
from datetime import datetime
import random
import torch.nn.functional as F
from models import create_model, get_model_name
from preparation import NetworkPacketPreprocessor, create_data_loaders
from config import (
    DATA_CONFIG, TRAINING_CONFIG, PATH_CONFIG,
    COLFORMER_DYNAMIC_SGP_CONFIG  
)


def set_seed(seed=42):
    """è®¾ç½®å…¨å±€éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§"""
    # Pythonéšæœºæ•°
    random.seed(seed)
    
    # NumPyéšæœºæ•°
    np.random.seed(seed)
    
    # PyTorchéšæœºæ•°
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # ç¡®ä¿CUDAæ“ä½œçš„ç¡®å®šæ€§
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # ä½¿ç”¨ç¡®å®šæ€§ç®—æ³• - ä½†å¯¹ä¸æ”¯æŒçš„æ“ä½œåªå‘å‡ºè­¦å‘Š
    torch.use_deterministic_algorithms(True, warn_only=True)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    logger.info(f"éšæœºç§å­å·²è®¾ç½®ä¸º: {seed}")

# è®¾ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
def setup_logging():
    # åˆ›å»ºæŒ‰æ—¥æœŸåˆ†ç±»çš„logsç›®å½•
    current_date = datetime.now().strftime("%Y-%m-%d")
    log_dir = Path(PATH_CONFIG['log_dir']) / current_date
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"training_{timestamp}.log"
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # é…ç½®æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),  # æ–‡ä»¶å¤„ç†å™¨
            logging.StreamHandler()  # æ§åˆ¶å°å¤„ç†å™¨
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—å°†ä¿å­˜åˆ°: {log_file}")
    return logger

logger = setup_logging()


class ProtocolTrainer:
    def __init__(self, model, train_loader, val_loader, test_loader, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.device = device
        
        # æ—©åœé…ç½® - ä¿®æ”¹ä¸ºåŸºäºF1æ”¹è¿›çš„æ—©åœ
        self.early_stop_patience = 3       # è¿ç»­æ²¡æœ‰æ”¹è¿›çš„epochæ•°
        self.early_stop_counter = 0        # è®¡æ•°å™¨

        
        # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´ç¨³å®šçš„å­¦ä¹ ç‡
        self.optimizer = optim.AdamW(
            model.parameters(), 
            lr=TRAINING_CONFIG['learning_rate'], 
            weight_decay=TRAINING_CONFIG['weight_decay']
        )
        

        self.criterion = nn.CrossEntropyLoss(ignore_index=-100)
        logger.info("ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±")

        self.scheduler = None
        logger.info("ä½¿ç”¨å›ºå®šå­¦ä¹ ç‡è®­ç»ƒ")

        # è®°å½•æœ€ä½³æ¨¡å‹ï¼ˆä»…ç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
        self.best_val_f1 = 0.0
        self.best_val_loss = float('inf')
        self.best_epoch = 0
        self.best_model_path = PATH_CONFIG['best_model_path']
        
        # è®­ç»ƒå†å²è®°å½•
        self.train_history = {
            'train_loss': [], 'train_f1': [],
            'val_loss': [], 'val_precision': [], 'val_recall': [], 'val_f1': [],
            'learning_rates': []
        }
        
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch - ä½¿ç”¨å•æ¡æµé‡å¾®å¹³å‡è¯„ä¼°"""
        self.model.train()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        progress_bar = tqdm(self.train_loader, desc="Training")
        
        for batch_idx, batch in enumerate(progress_bar):
            self.optimizer.zero_grad()
            
            bit_matrices = batch['bit_matrix'].to(self.device)
            labels = batch['labels'].to(self.device)
            protocols = batch['protocols']
            
            attention_mask = (bit_matrices.sum(dim=-1) > 0)
            
            # è·å–ç»“æ„ç‰¹å¾
            structure_features = batch.get('structure_features')
            if structure_features is not None:
                structure_features = structure_features.to(self.device)
            
            # åªè°ƒç”¨ ColFormerDynamicSGP æ¨¡å‹
            logits = self.model(
                bit_matrix=bit_matrices,
                structure_features=structure_features,
                attention_mask=attention_mask
            )
                 
            
            # åªè®¡ç®—äº¤å‰ç†µæŸå¤±
            ce_loss = self.criterion(logits.view(-1, 2), labels.view(-1))
            
            # åå‘ä¼ æ’­
            ce_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            total_loss += ce_loss.item()
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': ce_loss.item()
            })
            
            # æ”¶é›†é¢„æµ‹ç»“æœç”¨äºè®¡ç®—å¾®å¹³å‡æŒ‡æ ‡
            with torch.no_grad():
                preds = torch.argmax(logits, dim=2)
                mask = labels != -100
                
                # æ‰å¹³åŒ–æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„é¢„æµ‹å’Œæ ‡ç­¾
                for i in range(len(protocols)):
                    sample_mask = mask[i]
                    
                    if sample_mask.any():
                        sample_preds = preds[i][sample_mask].cpu().numpy()
                        sample_labels = labels[i][sample_mask].cpu().numpy()
                        
                        all_preds.extend(sample_preds.tolist())
                        all_labels.extend(sample_labels.tolist())
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / len(self.train_loader)
        
        # ä½¿ç”¨å¾®å¹³å‡è®¡ç®—è®­ç»ƒF1
        train_metrics = self.calculate_byte_level_metrics(all_preds, all_labels)
        train_f1 = train_metrics['f1']
        
        # è®°å½•æŸå¤±
        logger.info(f"è®­ç»ƒæŸå¤±: {avg_loss:.4f}")
        
        return avg_loss, train_f1
    
    def validate(self, data_loader, desc="Validation"):
        """éªŒè¯æ¨¡å‹ - ä½¿ç”¨å•æ¡æµé‡å¾®å¹³å‡è¯„ä¼°"""
        self.model.eval()
        total_loss = 0
        protocol_results = {}

        with torch.no_grad():
            for batch in tqdm(data_loader, desc=desc):
                bit_matrices = batch['bit_matrix'].to(self.device)
                labels = batch['labels'].to(self.device)
                protocols = batch['protocols']
                
                attention_mask = (bit_matrices.sum(dim=-1) > 0)
            
                # è·å–ç»“æ„ç‰¹å¾
                structure_features = batch.get('structure_features')
                if structure_features is not None:
                    structure_features = structure_features.to(self.device)
                
                # åªè°ƒç”¨ ColFormerDynamicSGP æ¨¡å‹
                logits = self.model(
                    bit_matrix=bit_matrices,
                    structure_features=structure_features,
                    attention_mask=attention_mask
                )

                loss = self.criterion(logits.view(-1, 2), labels.view(-1))
                total_loss += loss.item()

                preds = torch.argmax(logits, dim=2)
                mask = labels != -100

                # æŒ‰åè®®æ”¶é›†é¢„æµ‹ç»“æœï¼ˆæ‰å¹³åŒ–ï¼‰
                for i in range(len(protocols)):
                    protocol = protocols[i]
                    sample_mask = mask[i]
                    
                    if sample_mask.any():
                        sample_preds = preds[i][sample_mask].cpu().numpy()
                        sample_labels = labels[i][sample_mask].cpu().numpy()

                        if protocol not in protocol_results:
                            protocol_results[protocol] = {'preds': [], 'labels': []}
                        
                        # æ‰å¹³åŒ–æ”¶é›†æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
                        protocol_results[protocol]['preds'].extend(sample_preds.tolist())
                        protocol_results[protocol]['labels'].extend(sample_labels.tolist())

        avg_loss = total_loss / len(data_loader)

        # è®¡ç®—æ¯ä¸ªåè®®çš„å¾®å¹³å‡æŒ‡æ ‡
        protocol_metrics = {}
        
        for protocol, data in protocol_results.items():
            if data['labels'] and data['preds']:
                # ä½¿ç”¨å¾®å¹³å‡è®¡ç®—æ¯ä¸ªåè®®çš„æŒ‡æ ‡
                metrics = self.calculate_byte_level_metrics(
                    data['preds'], data['labels']
                )
                protocol_metrics[protocol] = metrics
                
                
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡ - ä½¿ç”¨å®å¹³å‡ï¼ˆåè®®é—´å¹³å‡ï¼‰
        if protocol_metrics:
            overall_metrics = {
                'precision': np.mean([m['precision'] for m in protocol_metrics.values()]),
                'recall': np.mean([m['recall'] for m in protocol_metrics.values()]),
                'f1': np.mean([m['f1'] for m in protocol_metrics.values()]),
                'tp': sum([m['tp'] for m in protocol_metrics.values()]),
                'fp': sum([m['fp'] for m in protocol_metrics.values()]),
                'fn': sum([m['fn'] for m in protocol_metrics.values()])
            }
        else:
            overall_metrics = {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'tp': 0, 'fp': 0, 'fn': 0}

        return {
            'loss': avg_loss,
            'overall': overall_metrics,
            'by_protocol': protocol_metrics
        }

    
    def calculate_byte_level_metrics(self, all_preds, all_labels):
        """
        å±‚æ¬¡ä¸€ï¼šå­—èŠ‚çº§è¾¹ç•Œè¯„ä¼° (Byte-level Boundary Evaluation)

        è®¡ç®—å­—èŠ‚çº§è¾¹ç•Œè¯„ä¼°çš„æ ¸å¿ƒæŒ‡æ ‡ï¼š
        - ç²¾ç¡®ç‡ (Precision): TP / (TP + FP)
        - å¬å›ç‡ (Recall): TP / (TP + FN)
        - F1åˆ†æ•° (F1-Score): 2 * (Precision * Recall) / (Precision + Recall)
        """
        if len(all_preds) == 0 or len(all_labels) == 0:
            return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'tp': 0, 'fp': 0, 'fn': 0}

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        preds = np.array(all_preds)
        labels = np.array(all_labels)

        # ç¬¬2æ­¥ï¼šé€ç‚¹æ¯”è¾ƒä¸è®¡æ•°
        # éå†æ¯ä¸€ä¸ªä½ç½®ï¼Œç´¯åŠ ä¸‰ç§æƒ…å†µçš„è®¡æ•°
        tp = np.sum((preds == 1) & (labels == 1))  # çœŸé˜³æ€§ï¼šæ¨¡å‹æ­£ç¡®æ‰¾åˆ°è¾¹ç•Œ
        fp = np.sum((preds == 1) & (labels == 0))  # å‡é˜³æ€§ï¼šæ¨¡å‹é”™è¯¯åˆ›é€ è¾¹ç•Œ
        fn = np.sum((preds == 0) & (labels == 1))  # å‡é˜´æ€§ï¼šæ¨¡å‹é—æ¼è¾¹ç•Œ

        # ç¬¬3æ­¥ï¼šè®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0

        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'tp': int(tp),
            'fp': int(fp),
            'fn': int(fn)
        }
    
    
    def save_best_model(self, epoch, val_f1, val_loss, val_precision, val_recall):
        """ä¿å­˜æœ€ä½³æ¨¡å‹ï¼šF1æœ€é«˜ï¼ŒF1ç›¸åŒæ—¶é€‰æ‹©val lossæœ€ä½çš„"""
        is_best = False
        
        if val_f1 > self.best_val_f1:
            # F1æ›´é«˜ï¼Œç›´æ¥ä¿å­˜
            is_best = True
            logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³F1: {val_f1:.4f} (ä¸Šä¸€æ¬¡: {self.best_val_f1:.4f})")
        elif val_f1 == self.best_val_f1 and val_loss < self.best_val_loss:
            # F1ç›¸åŒä½†éªŒè¯æŸå¤±æ›´ä½ï¼Œä¹Ÿä¿å­˜
            is_best = True
            logger.info(f"ğŸ‰ ç›¸åŒF1ä½†æ›´ä½éªŒè¯æŸå¤±: {val_loss:.4f} (ä¸Šä¸€æ¬¡: {self.best_val_loss:.4f})")
        
        if is_best:
            self.best_val_f1 = val_f1
            self.best_val_loss = val_loss
            self.best_epoch = epoch
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            model_state_dict = (self.model.module.state_dict() 
                              if isinstance(self.model, nn.DataParallel) 
                              else self.model.state_dict())
            
            checkpoint_data = {
                'epoch': epoch,
                'model_state_dict': model_state_dict,
                'optimizer_state_dict': self.optimizer.state_dict(),
                'val_f1': float(val_f1),
                'val_precision': float(val_precision),
                'val_recall': float(val_recall),
                'val_loss': float(val_loss),
                'train_history': self.train_history,
                'is_best_model': True
            }
            
            # åªæœ‰å½“schedulerå­˜åœ¨æ—¶æ‰ä¿å­˜å…¶çŠ¶æ€
            if self.scheduler is not None:
                checkpoint_data['scheduler_state_dict'] = self.scheduler.state_dict()
            
            torch.save(checkpoint_data, self.best_model_path)
            
            logger.info(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {self.best_model_path}")
        
        return is_best

    def train(self, num_epochs=5):
        """å®Œæ•´è®­ç»ƒæµç¨‹ - ä¿®æ”¹æ—©åœé€»è¾‘ä¸ºåŸºäºF1æ”¹è¿›"""
        logger.info(f"å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")

        for epoch in range(num_epochs):
            logger.info(f"\n=== Epoch {epoch+1}/{num_epochs} ===")
            
            # è®­ç»ƒ
            train_loss, train_f1 = self.train_epoch()
            
            # éªŒè¯
            val_results = self.validate(self.val_loader, "Validation")
            
            # è®°å½•å†å²
            overall = val_results['overall']
            current_lr = self.optimizer.param_groups[0]['lr']
            self.train_history['train_loss'].append(train_loss)
            self.train_history['train_f1'].append(train_f1)
            self.train_history['val_loss'].append(val_results['loss'])
            self.train_history['val_f1'].append(overall['f1'])
            self.train_history['val_precision'].append(overall['precision'])
            self.train_history['val_recall'].append(overall['recall'])
            self.train_history['learning_rates'].append(current_lr)
            
            # è®°å½•ç»“æœ
            logger.info(f"Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}")
            logger.info(f"Val Overall - Loss: {val_results['loss']:.4f}, F1: {overall['f1']:.4f}, "
                       f"Precision: {overall['precision']:.4f}, Recall: {overall['recall']:.4f}")
            logger.info(f"Learning Rate: {current_lr:.2e}")
            
            # æ˜¾ç¤ºå„åè®®æŒ‡æ ‡
            logger.info("å„åè®®éªŒè¯æŒ‡æ ‡:")
            for protocol, metrics in val_results['by_protocol'].items():
                logger.info(f"  {protocol:>8} - F1: {metrics['f1']:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹å¹¶æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›
            is_best = self.save_best_model(
                epoch, overall['f1'], val_results['loss'], 
                overall['precision'], overall['recall']
            )
            
            # æ—©åœæ£€æŸ¥ - åŸºäºF1æ”¹è¿›
            if is_best:
                # æœ‰æ”¹è¿›ï¼Œé‡ç½®è®¡æ•°å™¨
                self.early_stop_counter = 0
                logger.info(f"âœ… æ¨¡å‹æœ‰æ”¹è¿›ï¼Œé‡ç½®æ—©åœè®¡æ•°å™¨")
            else:
                # æ— æ”¹è¿›ï¼Œå¢åŠ è®¡æ•°å™¨
                self.early_stop_counter += 1
                logger.info(f"âš ï¸  è¿ç»­{self.early_stop_counter}ä¸ªepochæ— æ”¹è¿› "
                           f"(å½“å‰F1: {overall['f1']:.4f}, æœ€ä½³F1: {self.best_val_f1:.4f})")
                
                if self.early_stop_counter >= self.early_stop_patience:
                    logger.info(f"ğŸ›‘ è¿ç»­{self.early_stop_patience}ä¸ªepochæ— æ”¹è¿›ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                    break
        
        logger.info(f"\n=== è®­ç»ƒå®Œæˆ ===")
        if self.early_stop_counter >= self.early_stop_patience:
            logger.info(f"æå‰åœæ­¢äº Epoch {len(self.train_history['train_loss'])} (æ— æ”¹è¿›)")
        else:
            logger.info(f"æ­£å¸¸å®Œæˆè®­ç»ƒ (Epoch {len(self.train_history['train_loss'])})")
        
        logger.info(f"æœ€ä½³æ¨¡å‹æ¥è‡ª Epoch {self.best_epoch + 1}")
        logger.info(f"æœ€ä½³éªŒè¯F1: {self.best_val_f1:.4f}")
        logger.info(f"æœ€ä½³éªŒè¯Loss: {self.best_val_loss:.4f}")
        logger.info(f"æ€»è®­ç»ƒè½®æ•°: {len(self.train_history['train_loss'])}")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves()

    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        try:
            import matplotlib.pyplot as plt
            
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            epochs = range(1, len(self.train_history['train_loss']) + 1)
            
            # æŸå¤±æ›²çº¿
            axes[0, 0].plot(epochs, self.train_history['train_loss'], 'b-', label='Train Loss')
            axes[0, 0].plot(epochs, self.train_history['val_loss'], 'r-', label='Val Loss')
            axes[0, 0].set_title('Training and Validation Loss')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True)
            
            # F1åˆ†æ•°æ›²çº¿
            axes[0, 1].plot(epochs, self.train_history['train_f1'], 'b-', label='Train F1')
            axes[0, 1].plot(epochs, self.train_history['val_f1'], 'r-', label='Val F1')
            axes[0, 1].set_title('Training and Validation F1 Score')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('F1 Score')
            axes[0, 1].legend()
            axes[0, 1].grid(True)
            
            # ç²¾ç¡®ç‡å’Œå¬å›ç‡
            axes[1, 0].plot(epochs, self.train_history['val_precision'], 'g-', label='Precision')
            axes[1, 0].plot(epochs, self.train_history['val_recall'], 'orange', label='Recall')
            axes[1, 0].plot(epochs, self.train_history['val_f1'], 'r-', label='F1')
            axes[1, 0].set_title('Validation Metrics')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Score')
            axes[1, 0].legend()
            axes[1, 0].grid(True)
            
            # å­¦ä¹ ç‡æ›²çº¿
            axes[1, 1].plot(epochs, self.train_history['learning_rates'], 'purple', label='Learning Rate')
            axes[1, 1].set_title('Learning Rate Schedule')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plots_dir = Path("plots")
            plots_dir.mkdir(exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_path = plots_dir / f"training_curves_{timestamp}.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            logger.info(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {plot_path}")
            plt.close()
            
        except ImportError:
            logger.warning("matplotlibæœªå®‰è£…ï¼Œè·³è¿‡è®­ç»ƒæ›²çº¿ç»˜åˆ¶")
        except Exception as e:
            logger.error(f"ç»˜åˆ¶è®­ç»ƒæ›²çº¿æ—¶å‡ºé”™: {e}")

    def load_checkpoint(self, checkpoint_path=None):
        """åŠ è½½æ£€æŸ¥ç‚¹ï¼Œæ”¯æŒæ¢å¤è®­ç»ƒ"""
        if checkpoint_path is None:
            checkpoint_path = self.best_model_path
        
        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path, weights_only=False)
            
            # å¤„ç†DataParallelæ¨¡å‹çš„state_dicté”®åä¸åŒ¹é…é—®é¢˜
            model_state_dict = checkpoint['model_state_dict']
            
            is_model_parallel = isinstance(self.model, nn.DataParallel)
            has_module_prefix = any(key.startswith('module.') for key in model_state_dict.keys())
            
            if is_model_parallel and not has_module_prefix:
                model_state_dict = {f'module.{k}': v for k, v in model_state_dict.items()}
            elif not is_model_parallel and has_module_prefix:
                model_state_dict = {k.replace('module.', ''): v for k, v in model_state_dict.items()}
            
            self.model.load_state_dict(model_state_dict)
              
            if 'train_history' in checkpoint:
                self.train_history = checkpoint['train_history']
            
            self.best_val_f1 = checkpoint.get('val_f1', 0.0)
            
            logger.info(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
            logger.info(f"æœ€ä½³éªŒè¯F1: {self.best_val_f1:.4f}")
            return checkpoint.get('epoch', 0)
        else:
            logger.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return 0

    def test(self):
        """æµ‹è¯•æ¨¡å‹æ€§èƒ½ - å§‹ç»ˆåŠ è½½æœ€ä½³ä¿å­˜çš„æ¨¡å‹"""
        # åŠ è½½æœ€ä½³æ¨¡å‹
        if os.path.exists(self.best_model_path):
            checkpoint = torch.load(self.best_model_path, map_location=self.device, weights_only=False)
            model_state_dict = checkpoint.get('model_state_dict', checkpoint)
            
            # å¤„ç†DataParallelæ¨¡å‹çš„state_dicté”®åä¸åŒ¹é…é—®é¢˜
            is_model_parallel = isinstance(self.model, nn.DataParallel)
            has_module_prefix = any(key.startswith('module.') for key in model_state_dict.keys())
            
            if is_model_parallel and not has_module_prefix:
                model_state_dict = {f'module.{k}': v for k, v in model_state_dict.items()}
            elif not is_model_parallel and has_module_prefix:
                model_state_dict = {k.replace('module.', ''): v for k, v in model_state_dict.items()}
            
            self.model.load_state_dict(model_state_dict)
            
            best_epoch = checkpoint.get('epoch', 0) + 1
            best_f1 = checkpoint.get('val_f1', 0.0)
            best_loss = checkpoint.get('val_loss', 0.0)
            
            logger.info(f"âœ… åŠ è½½æœ€ä½³æ¨¡å‹ (Epoch {best_epoch})")
            logger.info(f"   éªŒè¯F1: {best_f1:.4f}, éªŒè¯Loss: {best_loss:.4f}")
        else:
            logger.warning(f"æœ€ä½³æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.best_model_path}")
            logger.info("ä½¿ç”¨å½“å‰è®­ç»ƒçŠ¶æ€çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
        
        # æµ‹è¯•é›†æµ‹è¯•
        test_results = None
        if self.test_loader:
            logger.info(f"\n--- æœªçŸ¥åè®®æµ‹è¯• - å­—èŠ‚çº§è¾¹ç•Œè¯„ä¼° (å…±è¯†è¯„ä¼°) ---")
            test_results = self.validate(self.test_loader, "Unknown Protocols Test")
            
            logger.info("\nå„åè®®è¯¦ç»†æŒ‡æ ‡:")
            for protocol, metrics in test_results['by_protocol'].items():
                logger.info(f"{protocol:>8} - F1: {metrics['f1']:.4f}, "
                           f"Prec: {metrics['precision']:.4f}, "
                           f"Recall: {metrics['recall']:.4f}")
        
        self.show_protocol_examples()
        
        return test_results

    def show_protocol_examples(self):
        """å±•ç¤ºå„åè®®çš„é¢„æµ‹æ ¼å¼ç¤ºä¾‹"""
        logger.info("\n" + "="*80)
        logger.info("åè®®æ ¼å¼é¢„æµ‹ç¤ºä¾‹")
        logger.info("="*80)

        self.model.eval()
        
        from config import PROTOCOLS
        target_protocols = PROTOCOLS
        
        if self.test_loader is None:
            logger.info("æ²¡æœ‰æµ‹è¯•é›†æ•°æ®")
            return

        with torch.no_grad():
            protocol_examples = {}
            
            for batch in self.test_loader:
                # ç»Ÿä¸€å¤„ç†è¾“å…¥
                bit_matrices = batch['bit_matrix'].to(self.device)
                labels = batch['labels'].to(self.device)
                protocols = batch['protocols']
                
                attention_mask = (bit_matrices.sum(dim=-1) > 0)
                
                # è·å–ç»“æ„ç‰¹å¾
                structure_features = batch.get('structure_features')
                if structure_features is not None:
                    structure_features = structure_features.to(self.device)
                
                # åªè°ƒç”¨ ColFormerDynamicSGP æ¨¡å‹
                logits = self.model(
                    bit_matrix=bit_matrices,
                    structure_features=structure_features,
                    attention_mask=attention_mask
                )

                preds = torch.argmax(logits, dim=2)
                mask = labels != -100

                for i in range(len(protocols)):
                    protocol = protocols[i]
                    sample_mask = mask[i]
                    
                    if sample_mask.any() and protocol in target_protocols:
                        # åªæ”¶é›†ç¬¬ä¸€ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹
                        if protocol not in protocol_examples:
                            sample_preds = preds[i][sample_mask].cpu().numpy()
                            sample_labels = labels[i][sample_mask].cpu().numpy()
                            sample_bits = bit_matrices[i][sample_mask].cpu().numpy()
                            
                            protocol_examples[protocol] = {
                                'preds': sample_preds,
                                'labels': sample_labels,
                                'bits': sample_bits
                            }

        # æ˜¾ç¤ºå„åè®®çš„ç¤ºä¾‹
        for protocol in target_protocols:
            if protocol in protocol_examples:
                logger.info(f"\n--- {protocol.upper()} åè®®ç¤ºä¾‹ ---")
                example = protocol_examples[protocol]
                
                # é‡æ„åå…­è¿›åˆ¶æ•°æ®
                hex_data = ""
                for i in range(len(example['bits'])):
                    byte_bits = example['bits'][i]
                    byte_value = 0
                    for j in range(8):
                        if byte_bits[j] > 0.5:
                            byte_value |= (1 << (7-j))
                    hex_data += f"{byte_value:02x}"
                
                pred_format = self._format_fields(hex_data, example['preds'])
                true_format = self._format_fields(hex_data, example['labels'])
                
                logger.info(f"æ•°æ®é•¿åº¦: {len(example['preds'])} å­—èŠ‚")
                logger.info(f"é¢„æµ‹æ ¼å¼: {pred_format}")
                logger.info(f"çœŸå®æ ¼å¼: {true_format}")
                
                # æ˜¾ç¤ºè¾¹ç•Œä½ç½®
                pred_boundaries = [i for i, label in enumerate(example['preds']) if label == 1]
                true_boundaries = [i for i, label in enumerate(example['labels']) if label == 1]
                
                logger.info(f"é¢„æµ‹è¾¹ç•Œä½ç½®: {pred_boundaries}")
                logger.info(f"çœŸå®è¾¹ç•Œä½ç½®: {true_boundaries}")
            
  


    def _format_fields(self, hex_data, boundary_seq):
        """æ ¹æ®è¾¹ç•Œåºåˆ—æ ¼å¼åŒ–å­—æ®µ"""
        boundary_positions = [i for i, label in enumerate(boundary_seq) if label == 1]
        
        if not boundary_positions:
            return hex_data  # æ²¡æœ‰è¾¹ç•Œï¼Œæ•´ä¸ªæ•°æ®ä½œä¸ºä¸€ä¸ªå­—æ®µ
        
        fields = []
        start_pos = 0
        
        for boundary_pos in boundary_positions:
            end_pos = boundary_pos + 1
            field_hex = hex_data[start_pos*2:end_pos*2]
            if field_hex:
                fields.append(field_hex)
            start_pos = end_pos
        
        # å¤„ç†æœ€åä¸€ä¸ªå­—æ®µ
        if start_pos < len(boundary_seq):
            remaining_hex = hex_data[start_pos*2:]
            if remaining_hex:
                fields.append(remaining_hex)
        
        return " | ".join(fields) if fields else hex_data

def run_cross_validation():
    """è¿è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯å®éªŒ"""
    from config import EXPERIMENT_CONFIG
    
    target_protocols = EXPERIMENT_CONFIG['target_protocols']
    all_results = {}
    
    logger.info("="*80)
    logger.info("å¼€å§‹ç•™ä¸€æ³•äº¤å‰éªŒè¯å®éªŒ")
    logger.info(f"ç›®æ ‡åè®®: {target_protocols}")
    logger.info("="*80)
    logger.info("ä½¿ç”¨å•æ¡æµé‡è¯„ä¼°æ¨¡å¼ (åè®®å†…å¾®å¹³å‡ + åè®®é—´å®å¹³å‡)")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é¢„å¤„ç†æ•°æ®
    preprocessor = NetworkPacketPreprocessor()
    dataset_cache_dir = Path("data/dataset")
    
    if not dataset_cache_dir.exists() or not any(dataset_cache_dir.iterdir()):
        logger.info("æœªæ‰¾åˆ°é¢„å¤„ç†çš„æ•°æ®é›†ï¼Œå¼€å§‹é¢„å¤„ç†...")
        preprocessor.save_cross_validation_datasets()
    else:
        logger.info("å‘ç°å·²é¢„å¤„ç†çš„æ•°æ®é›†ï¼Œç›´æ¥ä½¿ç”¨")
    
    model_name = get_model_name()
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²è®­ç»ƒçš„æ¨¡å‹
    checkpoint_dir = Path(PATH_CONFIG['checkpoint_dir']) / model_name
    existing_models = []
    if checkpoint_dir.exists():
        existing_models = [f for f in checkpoint_dir.glob("*_best.pth") if f.is_file()]
    
    retrain_all = False
    if existing_models:
        logger.info(f"\nå‘ç° {len(existing_models)} ä¸ªå·²è®­ç»ƒçš„æ¨¡å‹:")
        for model_file in existing_models:
            protocol = model_file.stem.replace('_best', '')
            logger.info(f"  - {protocol}")
    
        retrain_all = True  # é»˜è®¤é‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼Œä¾¿äºæµ‹è¯•
    
    for i, test_protocol in enumerate(target_protocols):
        logger.info(f"\n{'='*60}")
        logger.info(f"å®éªŒ {i+1}/{len(target_protocols)}: æµ‹è¯•åè®® {test_protocol}")
        logger.info(f"{'='*60}")
        
        # åŠ è½½é¢„å¤„ç†çš„æ•°æ®é›†
        train_dataset, val_dataset, test_dataset = preprocessor.load_cross_validation_dataset(
            test_protocol
        )

        if train_dataset is None or val_dataset is None or test_dataset is None:
            logger.error(f"åŠ è½½åè®® {test_protocol} æ•°æ®é›†å¤±è´¥ï¼Œè·³è¿‡")
            continue

        # ç»Ÿä¸€ä½¿ç”¨åè®®åˆ†ç»„æ•°æ®åŠ è½½å™¨ - é€‚é…åŒåè®®æµé‡åœºæ™¯
        logger.info("ä½¿ç”¨åè®®åˆ†ç»„æ•°æ®åŠ è½½å™¨ (é€‚é…åŒåè®®æµé‡åœºæ™¯)")
        train_loader, val_loader, test_loader = create_data_loaders(
            train_dataset, val_dataset, test_dataset, 
            batch_size=TRAINING_CONFIG['base_batch_size']
        )
        
        # æ›´æ–°æ¨¡å‹ä¿å­˜è·¯å¾„ - æŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»
        checkpoint_dir = Path(PATH_CONFIG['checkpoint_dir']) / model_name
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        model_path = checkpoint_dir / f"{test_protocol}_best.pth"
        PATH_CONFIG['best_model_path'] = str(model_path)
        
        logger.info(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {model_path}")
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model().to(device)
        if torch.cuda.device_count() > 1:
            model = nn.DataParallel(model)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = ProtocolTrainer(model, train_loader, val_loader, test_loader, device)
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦è®­ç»ƒ
        if os.path.exists(model_path) and not retrain_all:
            logger.info(f"ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹: {model_path}")
            test_results = trainer.test()
        else:
            if os.path.exists(model_path):
                logger.info(f"é‡æ–°è®­ç»ƒæ¨¡å‹ (æœªçŸ¥åè®®: {test_protocol})")
            else:
                logger.info(f"å¼€å§‹è®­ç»ƒ (æœªçŸ¥åè®®: {test_protocol})")
            trainer.train(num_epochs=TRAINING_CONFIG['num_epochs'])
            test_results = trainer.test()
        
        if test_results:
            all_results[test_protocol] = test_results['overall']
        
    
    # è¾“å‡ºæœ€ç»ˆç»“æœæ±‡æ€»
    if all_results:
        logger.info("\n" + "="*80)
        logger.info(f"ç•™ä¸€æ³•äº¤å‰éªŒè¯æœ€ç»ˆç»“æœæ±‡æ€» - {model_name}")
        logger.info("è¯„ä¼°ç­–ç•¥: åè®®å†…å¾®å¹³å‡ + åè®®é—´å®å¹³å‡")
        logger.info("="*80)
        
        f1_scores = []
        precision_scores = []
        recall_scores = []
        
        for protocol, metrics in all_results.items():
            f1_scores.append(metrics['f1'])
            precision_scores.append(metrics['precision'])
            recall_scores.append(metrics['recall'])
            logger.info(f"{protocol:>8} - F1: {metrics['f1']:.4f}, "
                       f"Precision: {metrics['precision']:.4f}, "
                       f"Recall: {metrics['recall']:.4f}")
        
        # è®¡ç®—å®å¹³å‡æŒ‡æ ‡ï¼ˆåè®®é—´å¹³å‡ï¼‰
        avg_f1 = np.mean(f1_scores)
        avg_precision = np.mean(precision_scores)
        avg_recall = np.mean(recall_scores)
        std_f1 = np.std(f1_scores)
        
        logger.info("-" * 80)
        logger.info(f"{'å®å¹³å‡':>8} - F1: {avg_f1:.4f}Â±{std_f1:.4f}, "
                   f"Precision: {avg_precision:.4f}, "
                   f"Recall: {avg_recall:.4f}")
        logger.info("è¯´æ˜: æ¯ä¸ªåè®®å†…ä½¿ç”¨å¾®å¹³å‡ï¼Œåè®®é—´ä½¿ç”¨å®å¹³å‡")
        logger.info("="*80)



def main():
    # é¦–å…ˆè®¾ç½®éšæœºç§å­
    set_seed(DATA_CONFIG['random_seed'])
    
    logger.info("="*80)
    logger.info("åè®®è¾¹ç•Œæ£€æµ‹è®­ç»ƒå¼€å§‹")
    logger.info(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"éšæœºç§å­: {DATA_CONFIG['random_seed']}")
    logger.info("="*80)
    

    
    selected_gpus = TRAINING_CONFIG['gpu_ids'] 
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, selected_gpus))
    logger.info(f"è®¾ç½®CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}")
    logger.info(f"ä½¿ç”¨GPU: {selected_gpus}")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: ColFormerDynamicSGP")
    
    # åªæ˜¾ç¤º ColFormerDynamicSGP çš„é…ç½®
    logger.info(f"æ¨¡å‹é…ç½®å‚æ•°: {COLFORMER_DYNAMIC_SGP_CONFIG}")
    
    # é‡æ–°åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # è®¾ç½®è®¾å¤‡å’Œå¤šGPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    gpu_count = torch.cuda.device_count()
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    logger.info(f"PyTorchå¯è§GPUæ•°é‡: {gpu_count}")
    
    # ç›´æ¥è¿è¡Œç•™ä¸€æ³•äº¤å‰éªŒè¯
    logger.info("å¼€å§‹ç•™ä¸€æ³•äº¤å‰éªŒè¯æ¨¡å¼...")
    run_cross_validation()

if __name__ == "__main__":
    main()
